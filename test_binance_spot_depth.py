#!/usr/bin/env python3
"""
æµ‹è¯•è„šæœ¬ï¼šéªŒè¯å¸å®‰ç°è´§è®¢å•ç°¿æ·±åº¦æ•°æ®æ”¶é›†çš„ä¿®å¤
"""

import json
import gzip
import sys
from collections import defaultdict

def analyze_spot_depth_continuity(file_path, max_lines=10000):
    """
    åˆ†æç°è´§æ·±åº¦æ•°æ®çš„è¿ç»­æ€§
    
    æ ¹æ®å¸å®‰APIæ–‡æ¡£ï¼Œç°è´§depthæ›´æ–°çš„è¿ç»­æ€§æ£€æŸ¥è§„åˆ™æ˜¯ï¼š
    - ç¬¬ä¸€ä¸ªäº‹ä»¶çš„ U <= lastUpdateId+1 AND u >= lastUpdateId+1
    - åç»­äº‹ä»¶éœ€è¦ U == prevU + 1
    
    å…¶ä¸­ U æ˜¯æœ¬æ¬¡æ›´æ–°çš„èµ·å§‹updateIdï¼Œu æ˜¯æœ¬æ¬¡æ›´æ–°çš„ç»“æŸupdateId
    """
    
    print("=" * 80)
    print(f"åˆ†ææ–‡ä»¶: {file_path}")
    print("=" * 80)
    
    depth_updates = defaultdict(list)
    missing_count = defaultdict(int)
    total_updates = defaultdict(int)
    
    with gzip.open(file_path, 'rt') as f:
        for i, line in enumerate(f):
            if i >= max_lines:
                break
            
            try:
                parts = line.strip().split(' ', 1)
                data = json.loads(parts[1])
                
                if 'depth' in data.get('stream', ''):
                    depth_data = data.get('data', {})
                    if depth_data.get('e') == 'depthUpdate':
                        symbol = depth_data.get('s')
                        U = depth_data.get('U')
                        u = depth_data.get('u')
                        
                        if symbol and U and u:
                            depth_updates[symbol].append({
                                'U': U,
                                'u': u,
                                'line': i + 1
                            })
                            total_updates[symbol] += 1
                            
            except Exception as e:
                continue
    
    # åˆ†ææ¯ä¸ªäº¤æ˜“å¯¹çš„è¿ç»­æ€§
    for symbol in sorted(depth_updates.keys()):
        updates = depth_updates[symbol]
        print(f"\näº¤æ˜“å¯¹: {symbol}")
        print(f"  æ€»æ›´æ–°æ•°: {total_updates[symbol]}")
        
        gaps = []
        prev_u = None
        
        for idx, update in enumerate(updates):
            U = update['U']
            u = update['u']
            
            if prev_u is not None:
                # æ£€æŸ¥è¿ç»­æ€§ï¼šU åº”è¯¥ <= prev_u + 1
                if U > prev_u + 1:
                    gap = U - prev_u - 1
                    gaps.append({
                        'position': idx,
                        'line': update['line'],
                        'gap': gap,
                        'prev_u': prev_u,
                        'U': U,
                        'u': u
                    })
                    missing_count[symbol] += 1
            
            prev_u = u
        
        if gaps:
            print(f"  âŒ å‘ç° {len(gaps)} ä¸ªé—´éš™:")
            for gap_info in gaps[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"     ä½ç½® {gap_info['position']}: é—´éš™ {gap_info['gap']} "
                      f"(prev_u={gap_info['prev_u']}, U={gap_info['U']})")
            if len(gaps) > 5:
                print(f"     ... è¿˜æœ‰ {len(gaps) - 5} ä¸ªé—´éš™")
        else:
            print(f"  âœ… æ•°æ®è¿ç»­ï¼Œæ— é—´éš™")
    
    print("\n" + "=" * 80)
    print("æ€»ç»“")
    print("=" * 80)
    total_symbols = len(depth_updates)
    problematic_symbols = sum(1 for s in depth_updates if missing_count[s] > 0)
    
    print(f"åˆ†æçš„äº¤æ˜“å¯¹æ•°é‡: {total_symbols}")
    print(f"æœ‰é—´éš™çš„äº¤æ˜“å¯¹: {problematic_symbols}")
    print(f"æ— é—´éš™çš„äº¤æ˜“å¯¹: {total_symbols - problematic_symbols}")
    
    if problematic_symbols == 0:
        print("\nâœ… æ‰€æœ‰äº¤æ˜“å¯¹çš„æ·±åº¦æ•°æ®éƒ½æ˜¯è¿ç»­çš„ï¼")
        return True
    else:
        print(f"\nâš ï¸  æœ‰ {problematic_symbols} ä¸ªäº¤æ˜“å¯¹å­˜åœ¨æ•°æ®é—´éš™")
        return False

def compare_old_new_logic():
    """
    è¯´æ˜æ—§é€»è¾‘å’Œæ–°é€»è¾‘çš„åŒºåˆ«
    """
    print("\n" + "=" * 80)
    print("å¸å®‰ç°è´§æ·±åº¦æ•°æ®è¿ç»­æ€§æ£€æŸ¥é€»è¾‘å¯¹æ¯”")
    print("=" * 80)
    
    print("\nã€æ—§é€»è¾‘ - é”™è¯¯ã€‘:")
    print("  if prev_u.is_none() || U != *prev_u.unwrap() + 1")
    print("  é—®é¢˜: è¦æ±‚ U å¿…é¡»ä¸¥æ ¼ç­‰äº prev_u + 1")
    print("  ä½†å¸å®‰ç°è´§çš„ U æ˜¯æœ¬æ‰¹æ¬¡æ›´æ–°çš„èµ·å§‹IDï¼Œå¯èƒ½ < prev_u + 1")
    
    print("\nã€æ–°é€»è¾‘ - æ­£ç¡®ã€‘:")
    print("  if U > prev_u_val + 1")
    print("  æ­£ç¡®: åªè¦ U <= prev_u + 1ï¼Œè¯´æ˜æ•°æ®æ˜¯è¿ç»­çš„")
    print("  è¿™ç¬¦åˆå¸å®‰APIæ–‡æ¡£çš„è¦æ±‚: U <= lastUpdateId+1 AND u >= lastUpdateId+1")
    
    print("\nã€ç¤ºä¾‹ã€‘:")
    print("  å‡è®¾ prev_u = 1000")
    print("  æ”¶åˆ°æ›´æ–°: U=998, u=1005")
    print("    æ—§é€»è¾‘: U(998) != prev_u+1(1001) â†’ è®¤ä¸ºæœ‰é—´éš™ âŒ")
    print("    æ–°é€»è¾‘: U(998) <= prev_u+1(1001) â†’ æ•°æ®è¿ç»­ âœ…")

if __name__ == '__main__':
    # æ˜¾ç¤ºé€»è¾‘å¯¹æ¯”
    compare_old_new_logic()
    
    # åˆ†æå®é™…æ•°æ®
    file_path = '/data/shared/hft-trading-data/binance/spot/btcusdt_20251017.gz'
    
    print("\n" + "=" * 80)
    print("å¼€å§‹åˆ†æå®é™…æ•°æ®...")
    print("=" * 80)
    
    import os
    if not os.path.exists(file_path):
        print(f"\næ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        print("è¯·ç¡®ä¿collectoræ­£åœ¨è¿è¡Œå¹¶æ”¶é›†æ•°æ®")
        sys.exit(1)
    
    is_continuous = analyze_spot_depth_continuity(file_path, max_lines=50000)
    
    if is_continuous:
        print("\nğŸ‰ ä¿®å¤æˆåŠŸï¼æ•°æ®æ”¶é›†æ­£å¸¸ã€‚")
        sys.exit(0)
    else:
        print("\nâš ï¸  ä»å­˜åœ¨é—®é¢˜ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒæŸ¥ã€‚")
        sys.exit(1)



